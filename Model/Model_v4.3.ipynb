{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPKI9weaMlDg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf  # Importa la biblioteca TensorFlow\n",
        "\n",
        "# Imprime la versión de TensorFlow instalada\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# Lista los dispositivos físicos disponibles (GPU, CPU, etc.)\n",
        "print(\"Devices \", tf.config.list_physical_devices())\n",
        "\n",
        "try:\n",
        "    # Intenta detectar si hay una TPU disponible\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(f'Running on a TPU with {tpu.num_accelerators()[\"TPU\"]} cores')\n",
        "except ValueError:\n",
        "    # Si no se encuentra una TPU, lanza un error indicando que no está conectado a una TPU\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please check the previous cell for instructions!')\n",
        "\n",
        "# Conecta la configuración de TensorFlow al cluster de la TPU detectada\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "\n",
        "# Inicializa el sistema TPU\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# Define la estrategia de distribución para utilizar la TPU en la ejecución de modelos\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de dependencias necesarias\n",
        "!pip install vit-keras tensorflow-addons optuna"
      ],
      "metadata": {
        "id": "RyXJyalbOG2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manejo de archivos, datos y memoria\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import gc\n",
        "from datetime import datetime\n",
        "\n",
        "# Procesamiento y visualización de datos\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning y Preprocesamiento\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TensorFlow y Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Input, Model\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Vision Transformer (ViT) SOLO DISPONIBLE HASTA LA VERSION 2.15 DE TENSORFLOW\n",
        "from vit_keras import vit\n",
        "\n",
        "# Optuna para optimización de hiperparámetros\n",
        "import optuna\n",
        "\n",
        "# Google Colab (solo si se ejecuta en Colab)\n",
        "from google.colab import drive, runtime\n",
        "\n",
        "# Montar Google Drive (solo si se ejecuta en Colab)\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LikJe1MmMqdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir parámetros globales\n",
        "IMG_SIZE = 224  # Tamaño de las imágenes de entrada (224x224 píxeles)\n",
        "BATCH_SIZE = 64  # Tamaño del batch, recomendado entre 16 y 128\n",
        "EPOCHS = 100  # Número máximo de épocas; Early Stopping finalizará antes si es necesario\n",
        "\n",
        "# Configuración de la base de datos\n",
        "TRAIN_ZIP_URL = \"url/de/la/base/de/datos/\"  # URL donde se encuentra la base de datos comprimida en .zip\n",
        "DATASET_DIR = \"/content/dataset\"  # Directorio donde se extraerá la base de datos\n"
      ],
      "metadata": {
        "id": "ou2JqrrxNXQC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar el archivo .zip que contiene la base de datos (en este caso desde Dropbox)\n",
        "!wget -O /content/dataset.zip $TRAIN_ZIP_URL\n",
        "\n",
        "# Extraer el contenido del archivo .zip en el directorio especificado\n",
        "!unzip /content/dataset.zip -d $DATASET_DIR"
      ],
      "metadata": {
        "id": "iP-349nMNaCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorios de las imágenes\n",
        "train_dir = '/content/dataset/train'  # Directorio de imágenes de entrenamiento\n",
        "val_dir = '/content/dataset/val'  # Directorio de imágenes de validación\n",
        "\n",
        "# Crear datasets de entrenamiento y validación\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',  # Detecta automáticamente las subcarpetas como etiquetas (ej: benign, malignant)\n",
        "    label_mode='int',  # Etiquetas en formato entero (0 para benign, 1 para malignant)\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),  # Ajusta el tamaño de imagen a 224x224\n",
        "    shuffle=True  # Mezcla las imágenes aleatoriamente\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Normalización de imágenes (Escala los píxeles de 0 a 1)\n",
        "def normalize(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Convierte valores de píxeles de [0,255] a [0,1]\n",
        "    return image, label\n",
        "\n",
        "# Aplicar normalización a los datasets\n",
        "train_dataset = train_dataset.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Optimización del rendimiento\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Cachear, barajar y pre-cargar datos para mejorar la eficiencia\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "glz4cJ2UNc5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo basado en Vision Transformer (ViT)\n",
        "def create_vit_model(img_size, dense_units, dropout_rate, l2_rate):\n",
        "    vit_base = vit.vit_b16(\n",
        "        image_size=img_size,\n",
        "        pretrained=True,  # Usa pesos preentrenados\n",
        "        include_top=False,  # Excluye la capa final preentrenada\n",
        "        pretrained_top=False,\n",
        "    )\n",
        "    inputs = Input(shape=(img_size, img_size, 3))\n",
        "\n",
        "    x = vit_base(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(dense_units, activation=\"relu\",\n",
        "                     kernel_regularizer=tf.keras.regularizers.l2(l2_rate))(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Definir Focal Loss con ajuste de alpha\n",
        "def focal_loss(gamma=2.0, alpha=0.75):\n",
        "    def loss(y_true, y_pred):\n",
        "        bce = tf.keras.losses.BinaryCrossentropy(\n",
        "            reduction=tf.keras.losses.Reduction.NONE\n",
        "        )(y_true, y_pred)\n",
        "        pt = tf.exp(-bce)\n",
        "        focal_loss_value = alpha * (1.0 - pt)**gamma * bce\n",
        "        return tf.reduce_mean(focal_loss_value)\n",
        "    return loss\n",
        "\n",
        "# Función objetivo para Optuna (optimización de hiperparámetros)\n",
        "def objective(trial):\n",
        "    # Definir los hiperparámetros a optimizar\n",
        "    dense_units = trial.suggest_int('dense_units', 128, 512)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.4, 0.7)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-4, log=True)\n",
        "    l2_rate = trial.suggest_float('l2_rate', 1e-6, 1e-2, log=True)\n",
        "\n",
        "    print(f\"\\n>>> Trial {trial.number} -- \"\n",
        "          f\"dense_units={dense_units}, \"\n",
        "          f\"dropout_rate={dropout_rate:.4f}, \"\n",
        "          f\"learning_rate={learning_rate:.6f}, \"\n",
        "          f\"l2_rate={l2_rate:.6f}\")\n",
        "\n",
        "    # Crear y compilar el modelo dentro del ámbito de TPU\n",
        "    with tpu_strategy.scope():\n",
        "        model = create_vit_model(\n",
        "            img_size=IMG_SIZE,\n",
        "            dense_units=dense_units,\n",
        "            dropout_rate=dropout_rate,\n",
        "            l2_rate=l2_rate,\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "            loss=focal_loss(alpha=0.75),  # Focal Loss ajustada para mejorar el recall\n",
        "            metrics=[\n",
        "                BinaryAccuracy(name=\"accuracy\"),\n",
        "                Precision(name=\"precision\"),\n",
        "                Recall(name=\"recall\"),\n",
        "                AUC(name=\"auc\"),\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    # Callbacks para optimizar el entrenamiento\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath=f\"/content/drive/MyDrive/Melanoma/Models/Model_v4/Model_v4.3.3(VIT)/Optuna/{trial.number}_optuna_checkpoint_model_v4.3.keras\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\"\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "        min_lr=1e-7\n",
        "    )\n",
        "\n",
        "    # Pesos de clase ajustados\n",
        "    class_weights = {0: 0.7, 1: 1.3}\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=EPOCHS,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stopping, checkpoint, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Retornar la mejor val_accuracy como métrica objetivo\n",
        "    val_accuracy = max(history.history['val_accuracy'])\n",
        "    return val_accuracy\n",
        "\n",
        "# Se puede cambiar la métrica objetivo para priorizar el recall si es necesario."
      ],
      "metadata": {
        "id": "GmEFccatTEkt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un estudio Optuna con almacenamiento en SQLite\n",
        "study = optuna.create_study(\n",
        "    study_name=\"model_v4.3_ViT_study\",  # Nombre del estudio\n",
        "    storage=\"sqlite:////content/drive/MyDrive/Melanoma/Models/Model_v4/Model_v4.3.3(VIT)/Optuna/model_v4.3_ViT_study.db\",  # Ruta donde se guardará el progreso\n",
        "    direction='maximize',  # Optimiza para maximizar la métrica objetivo (val_accuracy)\n",
        "    load_if_exists=True  # Si el estudio ya existe, lo carga en lugar de crearlo desde cero\n",
        ")\n",
        "\n",
        "# Ejecutar la optimización con 25 intentos (trials)\n",
        "study.optimize(objective, n_trials=25)\n",
        "\n",
        "# Mostrar los mejores hiperparámetros encontrados\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(f\"Best trial: {study.best_trial.number}\")\n",
        "print(f\"Best value (val_accuracy): {study.best_trial.value}\")"
      ],
      "metadata": {
        "id": "XNqmsK2MYlUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Liberar memoria y desconectar la sesión en Google Colab\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "Sib8s69JYRlD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
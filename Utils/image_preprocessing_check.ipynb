{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisi√≥n de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm  # Barra de progreso\n",
    "\n",
    "def format_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "# Rutas de los directorios principales (cada uno tiene 2 subdirectorios)\n",
    "dir1 = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\divided_dataset\\BalancedDatabase\\divided_dataset_original\\test\")\n",
    "dir2 = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\divided_dataset\\BalancedDatabase\\divided_dataset_original\\train\")\n",
    "dir3 = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\divided_dataset\\BalancedDatabase\\divided_dataset_original\\val\")\n",
    "directorio_duplicados = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\divided_dataset\\BalancedDatabase\\divided_dataset_original\\duplicados\")\n",
    "\n",
    "# Crear carpeta de duplicados si no existe\n",
    "os.makedirs(directorio_duplicados, exist_ok=True)\n",
    "\n",
    "# Lista de directorios principales a analizar\n",
    "directorios = [dir1, dir2, dir3]\n",
    "\n",
    "# Diccionario para almacenar hashes y rutas de archivos\n",
    "hash_dict = defaultdict(list)\n",
    "\n",
    "# Funci√≥n para calcular el hash perceptual de una imagen con tama√±o 224x224\n",
    "def calcular_hash(imagen_path):\n",
    "    try:\n",
    "        with Image.open(imagen_path) as img:\n",
    "            img = img.convert(\"RGB\")  # Convertir a RGB para evitar problemas de formato\n",
    "            img = img.resize((224, 224))  # Redimensionar a 224x224\n",
    "            return imagehash.phash(img)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error procesando {imagen_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Contar total de im√°genes para la barra de progreso (incluyendo subdirectorios)\n",
    "total_imagenes = sum(len(files) for d in directorios for _, _, files in os.walk(d))\n",
    "\n",
    "# Escanear im√°genes y almacenar hashes con tolerancia en la diferencia de hash\n",
    "print(\"\\nüîç Escaneando im√°genes...\")\n",
    "with tqdm(total=total_imagenes, desc=\"Procesando im√°genes\", unit=\"img\") as pbar:\n",
    "    for directorio in directorios:\n",
    "        for subdir, _, archivos in os.walk(directorio):  # Busca en subdirectorios\n",
    "            for archivo in archivos:\n",
    "                ruta_completa = os.path.join(subdir, archivo)\n",
    "\n",
    "                if os.path.isfile(ruta_completa) and archivo.lower().endswith((\"jpg\", \"jpeg\", \"png\")):\n",
    "                    hash_imagen = calcular_hash(ruta_completa)\n",
    "                    if hash_imagen is not None:\n",
    "                        # Permitir una diferencia de hasta 5 en el hash para considerar im√°genes similares\n",
    "                        encontrado = False\n",
    "                        for h in hash_dict.keys():\n",
    "                            if hash_imagen - h <= 2:  # Tolerancia de 2\n",
    "                                hash_dict[h].append((ruta_completa, subdir))\n",
    "                                encontrado = True\n",
    "                                break\n",
    "                        if not encontrado:\n",
    "                            hash_dict[hash_imagen].append((ruta_completa, subdir))\n",
    "\n",
    "                    pbar.update(1)  # Actualizar barra de progreso\n",
    "\n",
    "# Mover im√°genes duplicadas y renombrarlas\n",
    "contador_duplicados = 1  # Para identificar cada grupo de im√°genes duplicadas\n",
    "imagenes_movidas = 0\n",
    "\n",
    "print(\"\\nüìÇ Moviendo im√°genes duplicadas...\")\n",
    "with tqdm(total=len(hash_dict), desc=\"Moviendo duplicados\", unit=\"grupo\") as pbar:\n",
    "    for hash_valor, lista_imagenes in hash_dict.items():\n",
    "        if len(lista_imagenes) > 1:  # Si hay m√°s de una imagen con el mismo hash\n",
    "            for idx, (ruta_original, subdirectorio_origen) in enumerate(lista_imagenes, start=1):\n",
    "                nombre_original = os.path.basename(ruta_original)\n",
    "                nombre_subdirectorio = os.path.basename(subdirectorio_origen)  # Obtener nombre del subdirectorio\n",
    "                nuevo_nombre = f\"dup{contador_duplicados}_{idx}_{nombre_subdirectorio}_{nombre_original}\"\n",
    "                nueva_ruta = os.path.join(directorio_duplicados, nuevo_nombre)\n",
    "\n",
    "                # Mover la imagen renombrada a la carpeta duplicados\n",
    "                shutil.move(ruta_original, nueva_ruta)\n",
    "                imagenes_movidas += 1\n",
    "                print(f\"‚úî Movida: {ruta_original} ‚Üí {nueva_ruta}\")\n",
    "\n",
    "            contador_duplicados += 1  # Incrementar contador para el siguiente grupo de duplicados\n",
    "        pbar.update(1)  # Actualizar barra de progreso\n",
    "\n",
    "print(f\"\\n‚úÖ Proceso completado. Se han movido {imagenes_movidas} im√°genes duplicadas a '{directorio_duplicados}' üöÄ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisi√≥n de mismo color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Importar tqdm para la barra de progreso\n",
    "\n",
    "def is_single_color(image_path, tolerance):\n",
    "    \"\"\"Verifica si la imagen es aproximadamente de un solo color bas√°ndose en la desviaci√≥n est√°ndar.\"\"\"\n",
    "    # Leer la imagen en color\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Comprobar si la desviaci√≥n est√°ndar est√° por debajo del umbral de tolerancia\n",
    "    return np.std(image) < tolerance\n",
    "\n",
    "def move_single_color_images(directory, tolerance=15):\n",
    "    \"\"\"Identifica im√°genes predominantemente de un solo color y las mueve a una carpeta 'color'.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"El directorio {directory} no existe.\")\n",
    "        return\n",
    "\n",
    "    # Directorio donde se almacenar√°n las im√°genes de un solo color\n",
    "    color_dir = os.path.join(directory, 'color')\n",
    "    os.makedirs(color_dir, exist_ok=True)\n",
    "\n",
    "    # Obtener la lista de archivos en el directorio\n",
    "    file_list = [f for f in os.listdir(directory) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    # Procesar im√°genes con barra de progreso\n",
    "    for filename in tqdm(file_list, desc=\"Procesando im√°genes\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Verificar si la imagen es predominantemente de un solo color\n",
    "        if is_single_color(file_path, tolerance):\n",
    "            shutil.move(file_path, os.path.join(color_dir, filename))\n",
    "            print(f\"Imagen de un solo color movida: {filename} a {color_dir}\")\n",
    "\n",
    "# Funci√≥n para formatear rutas correctamente\n",
    "def format_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "# Configuraci√≥n de rutas\n",
    "path_to_images = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\All\\malignant\")\n",
    "\n",
    "# Uso de la funci√≥n\n",
    "move_single_color_images(path_to_images, tolerance=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detectar imagenes con pelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "def detect_hair_in_image(image_path):\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    # Convertir la imagen a escala de grises\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar bordes usando el algoritmo Canny\n",
    "    edges = cv2.Canny(gray, threshold1=50, threshold2=150)\n",
    "\n",
    "    # Aplicar un filtro para detectar √°reas oscuras (cabello suele ser oscuro en muchas im√°genes m√©dicas)\n",
    "    dark_mask = cv2.inRange(gray, 0, 70)\n",
    "\n",
    "    # Combinamos los bordes y las √°reas oscuras\n",
    "    combined = cv2.bitwise_and(edges, dark_mask)\n",
    "\n",
    "    # Contar los p√≠xeles significativos en la imagen combinada\n",
    "    count_non_zero = cv2.countNonZero(combined)\n",
    "\n",
    "    # Si hay suficientes p√≠xeles, asumimos que hay cabello en la imagen\n",
    "    # Este umbral es ajustable seg√∫n la sensibilidad deseada\n",
    "    return count_non_zero > 3000\n",
    "\n",
    "def move_images_with_hair(src_directory, dest_directory):\n",
    "    if not os.path.exists(src_directory):\n",
    "        print(f\"The directory {src_directory} does not exist.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(dest_directory, exist_ok=True)\n",
    "\n",
    "    # Recorrer todas las im√°genes en el directorio\n",
    "    for filename in os.listdir(src_directory):\n",
    "        file_path = os.path.join(src_directory, filename)\n",
    "\n",
    "        # Saltar directorios u otros archivos que no sean im√°genes (asumiendo .jpg y .png)\n",
    "        if os.path.isdir(file_path) or not (filename.endswith('.jpg') or filename.endswith('.png')):\n",
    "            continue\n",
    "\n",
    "        # Detectar cabello en la imagen\n",
    "        if detect_hair_in_image(file_path):\n",
    "            # Mover la imagen a la carpeta de destino\n",
    "            shutil.move(file_path, os.path.join(dest_directory, filename))\n",
    "            print(f\"Moved {filename} to {dest_directory}\")\n",
    "\n",
    "# Funci√≥n para formatear rutas correctamente\n",
    "def format_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "# Configuraci√≥n de rutas\n",
    "src_directory = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\All\\benign\")\n",
    "dest_directory = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\All\\benign\\hair\")\n",
    "\n",
    "# Uso\n",
    "move_images_with_hair(src_directory, dest_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division en conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def format_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "# Ruta de los directorios originales\n",
    "original_dataset_dir = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\All\")\n",
    "benign_dir = os.path.join(original_dataset_dir, 'benign')\n",
    "malignant_dir = os.path.join(original_dataset_dir, 'malignant')\n",
    "\n",
    "# Ruta de los directorios de destino\n",
    "base_dir = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\divided_dataset\\BalancedDatabase\\divided_dataset_original\")\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Funci√≥n para crear directorios si no existen\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Crear directorios principales\n",
    "create_dir(train_dir)\n",
    "create_dir(val_dir)\n",
    "create_dir(test_dir)\n",
    "\n",
    "# Crear subdirectorios para cada clase en cada conjunto\n",
    "for subset in [train_dir, val_dir, test_dir]:\n",
    "    create_dir(os.path.join(subset, 'benign'))\n",
    "    create_dir(os.path.join(subset, 'malignant'))\n",
    "\n",
    "# Funci√≥n para dividir y copiar im√°genes\n",
    "def split_and_copy(class_name, src_dir, train_size, val_size, test_size):\n",
    "    # Obtener lista de archivos\n",
    "    filenames = os.listdir(src_dir)\n",
    "    random.shuffle(filenames)\n",
    "    \n",
    "    total_images = len(filenames)\n",
    "    \n",
    "    # Calcular √≠ndices para divisi√≥n\n",
    "    train_end = train_size\n",
    "    val_end = train_size + val_size\n",
    "    \n",
    "    # Dividir archivos\n",
    "    train_files = filenames[:train_end]\n",
    "    val_files = filenames[train_end:val_end]\n",
    "    test_files = filenames[val_end:train_size + val_size + test_size]\n",
    "    \n",
    "    # Copiar archivos\n",
    "    for filename in train_files:\n",
    "        src = os.path.join(src_dir, filename)\n",
    "        dst = os.path.join(train_dir, class_name, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "    for filename in val_files:\n",
    "        src = os.path.join(src_dir, filename)\n",
    "        dst = os.path.join(val_dir, class_name, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "    for filename in test_files:\n",
    "        src = os.path.join(src_dir, filename)\n",
    "        dst = os.path.join(test_dir, class_name, filename)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "# Dividir y copiar im√°genes de la clase Benigna\n",
    "split_and_copy(\n",
    "    class_name='benign',\n",
    "    src_dir=benign_dir,\n",
    "    train_size=34623,\n",
    "    val_size=7419,\n",
    "    test_size=7420\n",
    ")\n",
    "\n",
    "# Dividir y copiar im√°genes de la clase Maligna\n",
    "split_and_copy(\n",
    "    class_name='malignant',\n",
    "    src_dir=malignant_dir,\n",
    "    train_size=7028,\n",
    "    val_size=1506,\n",
    "    test_size=1507\n",
    ")\n",
    "\n",
    "print(\"Divisi√≥n y copia completadas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation - Balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def format_path(path):\n",
    "    return os.path.normpath(path)\n",
    "\n",
    "# Ruta de los directorios originales\n",
    "input_dir = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\divided_dataset\\BalancedDatabase\\divided_dataset_original\\train\")\n",
    "output_dir = format_path(r\"C:\\Users\\Marc\\Desktop\\UNI\\TFG\\DATABASE_build\\Sources\\MAIN_DATASET\\divided_dataset\\BalancedDatabase\\FinalDatabase_trainAugmented\\train\")\n",
    "\n",
    "# Asegura de que el directorio de salida existe\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Clases\n",
    "classes = ['benign', 'malignant']\n",
    "\n",
    "# ------------------------- #\n",
    "# FUNCIONES DE TRANSFORMACI√ìN\n",
    "# ------------------------- #\n",
    "def rotate_with_zoom(img_cv, angle, zoom=1.0):\n",
    "    height, width = img_cv.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, zoom)\n",
    "    rotated_img = cv2.warpAffine(\n",
    "        img_cv, rotation_matrix, (width, height),\n",
    "        flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE\n",
    "    )\n",
    "    return rotated_img\n",
    "\n",
    "def adjust_brightness(img_cv, factor):\n",
    "    hsv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2HSV).astype(np.float32)\n",
    "    hsv[:, :, 2] *= factor\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)\n",
    "    hsv = hsv.astype(np.uint8)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def adjust_contrast(img_cv, factor):\n",
    "    lab = cv2.cvtColor(img_cv, cv2.COLOR_RGB2LAB).astype(np.float32)\n",
    "    lab[:, :, 0] *= factor\n",
    "    lab[:, :, 0] = np.clip(lab[:, :, 0], 0, 255)\n",
    "    lab = lab.astype(np.uint8)\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def horizontal_flip(img_cv):\n",
    "    return cv2.flip(img_cv, 1)\n",
    "\n",
    "def vertical_flip(img_cv):\n",
    "    return cv2.flip(img_cv, 0)\n",
    "\n",
    "def random_shift(img_cv, max_shift=0.2):\n",
    "    h, w = img_cv.shape[:2]\n",
    "    shift_x = random.uniform(-max_shift, max_shift) * w\n",
    "    shift_y = random.uniform(-max_shift, max_shift) * h\n",
    "    M = np.float32([[1, 0, shift_x],\n",
    "                    [0, 1, shift_y]])\n",
    "    shifted = cv2.warpAffine(\n",
    "        img_cv, M, (w, h),\n",
    "        flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE\n",
    "    )\n",
    "    return shifted\n",
    "\n",
    "def random_blur(img_cv, max_ksize=3):\n",
    "    ksize = random.choice([1, 3])\n",
    "    if ksize == 1:\n",
    "        return img_cv  # sin blur\n",
    "    return cv2.GaussianBlur(img_cv, (ksize, ksize), 0)\n",
    "\n",
    "# ------------------------- #\n",
    "# LISTA / DICCIONARIO DE TRANSFORMACIONES POSIBLES\n",
    "# ------------------------- #\n",
    "def apply_random_transformation(img_cv):\n",
    "    transformations = {\n",
    "        'rotate_zoom': lambda img: rotate_with_zoom(\n",
    "            img,\n",
    "            angle=random.uniform(-45, 45),\n",
    "            zoom=random.uniform(0.9, 1.1)\n",
    "        ),\n",
    "        'brightness': lambda img: adjust_brightness(\n",
    "            img, factor=random.uniform(0.8, 1.2)\n",
    "        ),\n",
    "        'contrast': lambda img: adjust_contrast(\n",
    "            img, factor=random.uniform(0.8, 1.2)\n",
    "        ),\n",
    "        'flipH': lambda img: horizontal_flip(img),\n",
    "        'flipV': lambda img: vertical_flip(img),\n",
    "        'shift': lambda img: random_shift(img, max_shift=0.2),\n",
    "        'blur': lambda img: random_blur(img, max_ksize=3)\n",
    "    }\n",
    "    \n",
    "    chosen_key = random.choice(list(transformations.keys()))\n",
    "    transformed_img_cv = transformations[chosen_key](img_cv)\n",
    "    return transformed_img_cv, chosen_key\n",
    "\n",
    "# ------------------------- #\n",
    "# PROCESAMIENTO DE IM√ÅGENES\n",
    "# ------------------------- #\n",
    "for cls in classes:\n",
    "    class_input_dir = os.path.join(input_dir, cls)\n",
    "    class_output_dir = os.path.join(output_dir, cls)\n",
    "    if not os.path.exists(class_output_dir):\n",
    "        os.makedirs(class_output_dir)\n",
    "\n",
    "    print(f\"Procesando clase: {cls}\")\n",
    "\n",
    "    image_files = [\n",
    "        f for f in os.listdir(class_input_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "\n",
    "    for filename in tqdm(image_files, desc=f\"Procesando {cls}\", unit=\"imagen\"):\n",
    "        img_path = os.path.join(class_input_dir, filename)\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Leer imagen en RGB\n",
    "        img_cv = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if cls == 'benign':\n",
    "            # 1) Imagen original\n",
    "            # 2) UNA transformaci√≥n aleatoria\n",
    "            transformations = [(img_cv, 'orig')]\n",
    "\n",
    "            transformed_img, trans_name = apply_random_transformation(img_cv)\n",
    "            transformations.append((transformed_img, trans_name))\n",
    "\n",
    "        elif cls == 'malignant':\n",
    "            # 1 imagen original + 9 transformaciones\n",
    "            transformations = [(img_cv, 'orig')]\n",
    "            for _ in range(9):\n",
    "                transformed_img, trans_name = apply_random_transformation(img_cv)\n",
    "                transformations.append((transformed_img, trans_name))\n",
    "\n",
    "        # Guardar las im√°genes transformadas\n",
    "        for idx, (transformed_img_cv, trans_name) in enumerate(transformations):\n",
    "            output_filename = f\"{base_filename}_{idx+1}_{trans_name}.jpg\"\n",
    "            output_path = os.path.join(class_output_dir, output_filename)\n",
    "            transformed_img_bgr = cv2.cvtColor(transformed_img_cv, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(output_path, transformed_img_bgr)\n",
    "\n",
    "# ------------------------- #\n",
    "# BALANCEAR LAS CLASES\n",
    "# ------------------------- #\n",
    "print(\"Balanceando las clases...\")\n",
    "benign_dir = os.path.join(output_dir, 'benign')\n",
    "malignant_dir = os.path.join(output_dir, 'malignant')\n",
    "\n",
    "benign_images = [\n",
    "    f for f in os.listdir(benign_dir)\n",
    "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "]\n",
    "malignant_images = [\n",
    "    f for f in os.listdir(malignant_dir)\n",
    "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "]\n",
    "\n",
    "# Funci√≥n que retorna s√≥lo las im√°genes 'augmentadas' (sin '_orig')\n",
    "def get_augmented_images(file_list):\n",
    "    return [f for f in file_list if \"_orig\" not in f]\n",
    "\n",
    "# Al eliminar, nos aseguramos de borrar s√≥lo las im√°genes aumentadas\n",
    "if len(benign_images) > len(malignant_images):\n",
    "    # Exceso en benign\n",
    "    excess_count = len(benign_images) - len(malignant_images)\n",
    "    benign_aug = get_augmented_images(benign_images)  # s√≥lo augmentations\n",
    "    if len(benign_aug) >= excess_count:\n",
    "        to_remove = random.sample(benign_aug, excess_count)\n",
    "        for filename in to_remove:\n",
    "            os.remove(os.path.join(benign_dir, filename))\n",
    "            print(f\"Eliminada imagen aumentada: {filename} de benign\")\n",
    "    else:\n",
    "        # Si no hay suficientes augmentations para borrar, se borran todas las disponibles\n",
    "        for filename in benign_aug:\n",
    "            os.remove(os.path.join(benign_dir, filename))\n",
    "            print(f\"Eliminada imagen aumentada: {filename} de benign\")\n",
    "        print(\"No hab√≠a suficientes augmentations para equilibrar totalmente, pero se han eliminado todas las disponibles.\")\n",
    "\n",
    "elif len(malignant_images) > len(benign_images):\n",
    "    # Exceso en malignant\n",
    "    excess_count = len(malignant_images) - len(benign_images)\n",
    "    malignant_aug = get_augmented_images(malignant_images)  # s√≥lo augmentations\n",
    "    if len(malignant_aug) >= excess_count:\n",
    "        to_remove = random.sample(malignant_aug, excess_count)\n",
    "        for filename in to_remove:\n",
    "            os.remove(os.path.join(malignant_dir, filename))\n",
    "            print(f\"Eliminada imagen aumentada: {filename} de malignant\")\n",
    "    else:\n",
    "        # Si no hay suficientes augmentations para borrar, se borran todas las disponibles\n",
    "        for filename in malignant_aug:\n",
    "            os.remove(os.path.join(malignant_dir, filename))\n",
    "            print(f\"Eliminada imagen aumentada: {filename} de malignant\")\n",
    "        print(\"No hab√≠a suficientes augmentations para equilibrar totalmente, pero se han eliminado todas las disponibles.\")\n",
    "\n",
    "print(\"Clases balanceadas.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
